>   **SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report \#1 – Introduction to Testing and Defect Tracking**

| Group:  11      |
|-----------------|
|Ryan Khryss Obiar|   
|Armin Sandhu     |   
|Parsa Kargari    |   
|Jayden Mikulcik  |  


**Table of Contents**

(When you finish writing, update the following list using right click, then
“Update Field”)

[1 Introduction	1](#Introduction)

[2 High-level description of the exploratory testing plan	1](#High-level-description-of-the-exploratory-testing-plan)

[3 Comparison of exploratory and manual functional testing	1](#Comparison-of-exploratory-and-manual-functional-testing)

[4 Notes and discussion of the peer reviews of defect reports	1](#Notes-and-discussion-of-the-peer-reviews-of-defect-reports)

[5 How the pair testing was managed and team work/effort was divided	1](#How-the-pair-testing-was-managed-and-team-work/effort-was-divided )

[6 Difficulties encountered, challenges overcome, and lessons learned	1](#Difficulties-encountered,-challenges-overcome,-and-lessons-learned)

[7 Comments/feedback on the lab and lab document itself	1](#Comments/feedback-on-the-lab-and-lab-document-itself)

# Introduction
In this lab, our focus was on exploring the concepts of exploratory testing, manual functional testing and regression testing within the provided ATM application. Our group shared a common understanding of testing as a method to identify and address potential issues or bugs within an application's functionalities. 

Throughout this lab, we were to focus on the ATM application that handled customer transactions, including deposits, withdrawals, account transfers, and obtaining bank statements. Our objective was to assess the functionality of the application, ensuring that each feature operated as intended, and if not, identify and log bugs that occurred.

This hands-on experience ultimately broadened our understanding of testing methodologies in terms of the different types of testings, such as exploratory and manual functional testing. We learned how to perform these said methods, and why they are important when testing various software functionalities.

# High-level description of the exploratory testing plan

After carefully reviewing the requirements, my group intends to look at each requirement and test its given edge case. We will make sure to test all requirements stated in Appendix B, to make sure the ATM system functions as expected. These tests will be carried in the particular order in which a random user would enter and use the ATM machine, in this way we are able to ensure that the majority of the functions, with their test cases are being tested. We will test the various customer-side functionalities stated (inserting PIN, inserting cash, picking the transactions to execute). As well as this we will see how the system reacts and ensure it carries out its required actions (ie. Dispensing multiples of $20, printing out a receipt after all successful transactions, retaining customer card after 3 unsuccessful PIN attempts, etc.). Listing those examples, we've decided to divide the testing of the ATM Simulation into:

- ATM Booting: Consists of turning on the ATM, accepting cash value, card insertion and pin validation.
- Withdrawal: Consists of withdrawing cash from the ATM.
- Deposit: Consists of depositing cash into the ATM.
- Transfer: Consists of transferring cash from one account to another.
- Balance Inquiry: Consists of checking the balance of the account.

Although the tests will be carried out in and divided into these categories, we will also be testing the ATM system as a whole, to ensure that the system is able to handle multiple transactions at once, and that the system is able to handle multiple customers at once.

We decided that testing functions extensively would be good in this situation. Because we did not develop the code behind the ATM system, testing functions more extensively would not only give us greater insight into the system, but really uncover the different edge cases that may not be covered by the code. 

To come up with test cases, my pair will follow the general path of multiple scenarios of customer interaction with the ATM machine. First, we will go through the scenario of a custom successfully inputting their card and PIN, as well as successfully completing a transaction. Then, we will move only the scenario of a customer inputting their card and PIN  correctly, but unsuccessfully depositing money. Next, we will move on the scenario of a customer not inputting their PIN correctly, etc. It's important to follow the general path of multiple scenarios of customer interaction with the ATM machine, as it will allow us to uncover different edge cases that may not be covered by the code.

We believe that by using this general plan, we will be able to encounter most scenarios the ATM will be used with, and uncover/report different edge-cases accordingly. We will also try to alternate roles of ‘Tester’ and ‘Reporter’ in the pair, so that each of us can interact with the system in our own way.

# Comparison of exploratory and manual functional testing

Having the opportunity to explore the application without being restricted to a predefined set of tests allowed us to deepen our understanding of the application as a whole. This approach of exploratory testing helped us become more familiar with the application's functionalities allowing our test cases to be created in such a way that encapsulated the majority of the functionalities of the application. Writing test cases was tedious but could be easily retractable as the steps to recreate the bug were noted.

Through manual functional testing, we observed that the tests during the exploratory testing phase were common as they gave us pre-defined cases that encapsulated the main functionalities of the application. Through our comparisons, we were able to gain confidence that the bugs in our exploratory phase were prominent as it was duplicated in the manual function testing.

Within the provided Google sheets that involved our tests, we highlighted the ones that were bugs in both the exploratory phase and manual function testing (for 1.0) as well as our regression testing on version 1.1. Understanding the functionalities and requirements of this application helped our exploratory phase in terms of the functionality and expected output and how to get to that point, with this we were able to figure out if the test failed or passed according to our expected output. 

Repeating the same action for the manual function testing, we highlighted the test cases that failed the expected output and highlighted them as bugs. We listed duplicated bugs seen on both exploratory and manual function testing, giving us confidence in our exploratory phase knowing we were on the right track. 

https://docs.google.com/spreadsheets/d/16qokWTbmmYS8qSWSZK9tQz2gKNsEY_-cvs_1UqQvZmg/edit?usp=sharing 

# Notes and discussion of the peer reviews of defect reports

While undergoing peer reviews as advised in the guide to this lab, our group was able to come up with more comprehensive and full understandings of the bugs and requirements of the ATM machine. Allowing a second set of eyes to overlook the requirements of the ATM made missing the bugs a lot less likely in testing. One example of this was when one of our group members (Jayden) was testing test 14 in the Manual Scripting Testing and missed that the expected output did not match. The partner doing the peer review with him (Ryan) was able to spot that the expected output was not the same. 

Another benefit of using the peer review was allowing all testers to be exposed to more of the ATM system giving each a more complete and rounded understanding of the requirements of the ATM. Our overall notes on the implementation of peer review was greatly positive and the discussions we underwent when doing our review was essential in catching all the bugs and completing an accurate report. 

Having different pairs work on the same ATM simulation introduced many testing similarities. Therefore, it was beneficial to have a peer review of the defect reports. This allowed for a second set of eyes to overlook the requirements of the ATM and the bugs that were found. This was beneficial as it allowed for the bugs to be caught and reported accurately.

# How the pair testing was managed and team work/effort was divided 

For communication, we used iMessages to keep in contact with each other. We found that this was the most efficient way to communicate with each other and keep one another updated. We also used Google Sheets to record our test cases and the results of our tests. This allowed us to keep track of our tests and the results of our tests. We found that this was the most efficient way to record our tests and the results of our tests as it made it easy to collaborate easily within the group.

To streamline our testing process, we divided our group into two teams, each including two members (pair):

- Pair 1: Armin and Parsa
- Pair 2: Ryan and Jayden

This division of tasks allowed for one member to focus on actively testing the application, while the other is in charge of recording the outcomes of each tests, dictating whether they pass or is considered a bug. In the event of a filed test (bug), that member will be in charge or writing down the actual outcome that differs from the expected and, if available, the system log. 

Each pair does something similar, and in our case for this assignment, we "duplicated" our tests in terms of each pair doing the exploratory, MFT and regression. Having two groups doing the same type of testing, we were able to get majority of the validation of tests to make sure that we didn't miss one or mistakenly logged a bug that was actually a pass.

# Difficulties encountered, challenges overcome, and lessons learned

As mentioned earlier, one of the difficulties was the validation but was solved through having both pairs working on the same tests. Having two different "perspectives" to work on the same test allowed us to see the mistakes that we may have encountered, such as test being false positives/negatives. Through this, we were able to overcome this challenge and learned that this may be good validation of testing as both pairs were confident in the end of each type of testing. 

Initially, getting familiar with the ATM application was a challenge as we had to understand the functionalities and requirements of the application. However, as we progressed through the lab, we were able to understand the application better and were able to come up with test cases that encapsulated the main functionalities of the application.

# Comments/feedback on the lab and lab document itself

Overall our collective comment on this lab was it was essential in setting us up for success in this class. The introduction to the ideas and thought process behind testing while stripping us of the burden of coding really allowed us to understand the workflow of testing. This paired with the regression testing allowing us to see the timeline a bug patch should undergo and understanding of fixing bugs and ensuring that the old “product” does not break.

In general the feedback for this lab is greatly positive however one thing we would maybe change in the future is maybe using a more interactive “product” to test on as the functionality of an ATM is so rigid. Overall though the lab we felt was essential in dipping our foot into this class and the sentiment behind it is positive. 

