>   **SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report \#1 – Introduction to Testing and Defect Tracking**

| Group:  11      |
|-----------------|
|Ryan Khryss Obiar|   
|Armin Sandhu     |   
|Parsa Kargari    |   
|Jayden Mikulcik  |  


**Table of Contents**

(When you finish writing, update the following list using right click, then
“Update Field”)

[1 Introduction	1](#_Toc439194677)

[2 High-level description of the exploratory testing plan	1](#_Toc439194678)

[3 Comparison of exploratory and manual functional testing	1](#_Toc439194679)

[4 Notes and discussion of the peer reviews of defect reports	1](#_Toc439194680)

[5 How the pair testing was managed and team work/effort was divided	1](#_Toc439194681)

[6 Difficulties encountered, challenges overcome, and lessons learned	1](#_Toc439194682)

[7 Comments/feedback on the lab and lab document itself	1](#_Toc439194683)

# Introduction
In this lab, our focus was on exploring the concepts of exploratory and manual functional testing within the provided ATM application. Our group shared a common understanding of testing as a method to identify and address potential issues or bugs within an application's functionalities. 

Throughout this lab, we were to focus on the ATM application that handled customer transactions, including deposits, withdrawals, account transfers, and obtaining bank statements. Our objective was to assess the functionality of the application, ensuring that each feature operated as intended or identify and log bugs that occurred.

This hands-on experience broadened our understanding of testing methodologies in terms of the difference of testings, such as exploratory and manual functional testing.

# High-level description of the exploratory testing plan

After carefully reviewing the requirements, my group intends to look at each requirement and test its given edge case. We will make sure to test all requirements stated in Appendix B, to make sure the ATM system functions as expected. We will test the various customer-side functionalities stated (inserting PIN, inserting cash, picking the transactions to execute). As well as this we will see how the system reacts and ensure it carries out its required actions (ie. Dispensing multiples of $20, printing out a receipt after all successful transactions, retaining customer card after 3 unsuccessful PIN attempts, etc.). 

We decided that testing functions extensively would be good in this situation. Because we did not develop the code behind the ATM system, testing functions more extensively would not only give us greater insight into the system, but really uncover the different edge cases that may not be covered by the code. 

To come up with test cases, my pair will follow the general path of multiple scenarios of customer interaction with the ATM machine. First, we will go through the scenario of a custom successfully inputting their card and PIN, as well as successfully completing a transaction. Then, we will move only the scenario of a customer inputting their card and PIN  correctly, but unsuccessfully depositing money. Next, we will move on the scenario of a customer not inputting their PIN correctly, etc. 

We believe that by using this general plan, we will be able to encounter most scenarios the ATM will be used with, and uncover/report different edge-cases accordingly. We will also try to alternate roles of ‘Tester’ and ‘Reporter’ in the pair, so that each of us can interact with the system in our own way.

# Comparison of exploratory and manual functional testing

Having the opportunity to explore the application without being restricted to a predefined set of tests allowed our understanding of the application as a whole, to be fundamentally created. This approach of exploratory testing helped us become more familiar with the application's functionalities allowing our test cases to be created in such a way that encapsulated the majority of the functionalities of the application. Writing test cases was tedious but could be easily retractable as the steps to recreate the bug were noted.

Through manual functional testing, we observed that the tests during the exploratory testing phase were common as they gave us pre-defined cases that encapsulated the main functionalities of the application. Through our comparisons, we were able to gain confidence that the bugs in our exploratory phase were prominent as it was duplicated in the MFT.

Within the provided Google sheets that involved our tests, we highlighted the ones that were bugs in both the exploratory phase and MFT (for 1.0) as well as our regression testing on version 1.1. Understanding the functionalities and requirements of this application helped our exploratory phase in terms of the functionality and expected output and how to get to that point, with this we were able to figure out if the test failed or passed according to our expected output. 

Repeating the same action for the MFT, we highlighted the test cases that failed the expected output and highlighted them as bugs. We listed duplicated bugs seen on both exploratory and MFT, giving us confidence in our exploratory phase knowing we were on the right track. 

https://docs.google.com/spreadsheets/d/16qokWTbmmYS8qSWSZK9tQz2gKNsEY_-cvs_1UqQvZmg/edit?usp=sharing 

# Notes and discussion of the peer reviews of defect reports

  While undergoing peer reviews as advised in the guide to this lab our group was able to come up with more comprehensive and full understandings of the bugs and requirements of the ATM machine. Allowing a second set of eyes to overlook the requirements of the ATM made missing the bugs a lot less likely in testing. One example of this was when one of our group members (Jayden) was testing test 14 in the Manual Scripting Testing and missed that the expected output did not match. The partner doing the pier review with him (Ryan) was able to spot that the expected output was not the same. 

  Another benefit of using the peer review was allowing all testers to be exposed to more of the ATM system giving each a more complete and rounded understanding of the requirements of the ATM. Our overall notes on the implementation of peer review was greatly positive and the discussions we underwent when doing our review was essential in catching all the bugs and completing an accurate report. 

# How the pair testing was managed and team work/effort was divided 

To streamline our testing process, we divided our group into two teams, each including two members (pair). This division of tasks allowed for one member to focus on actively testing the application, while the other is in charge of recording the outcomes of each tests, dictating wether they pass or is considered a bug. In the event of a filed test (bug), that member will be in charge or writing down the actual outcome that differs from the expected and, if available, the system log. 

Each pair does something similar, and in our case for this assignment, we "duplicated" our tests in terms of each pair doing the exploratory, MFT and regression. Having two groups doing the same type of testing, we were able to get majority of the validation of tests to make sure that we didn't miss one or mistakenly logged a bug that was actually a pass. 

# Difficulties encountered, challenges overcome, and lessons learned

As mentioned earlier, one of the difficulties was the validation but was solved through having both pairs working on the same tests. Having two different "perspectives" to work on the same test allowed us to see the mistakes that we may have encountered, such as test being false positives/negatives. Through this, we were able to overcome this challenge and learned that this may be good validation of testing as both pairs were confident in the end of each type of testing. 

# Comments/feedback on the lab and lab document itself

Overall our collective comment on this lab was it was essential in setting us up for success in this class. The introduction to the ideas and thought process behind testing while stripping us of the burden of coding really allowed us to understand the workflow of testing. This paired with the regression testing allowing us to see the timeline a bug patch should undergo and understanding of fixing bugs and ensuring that the old “product” does not break.

In general the feedback for this lab is greatly positive however one thing we would maybe change in the future is maybe using a more interactive “product” to test on as the functionality of an ATM is so rigid. Overall though the lab we felt was essential in dipping our foot into this class and the sentiment behind it is positive. 

